{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bull/anaconda/envs/farmdrive/lib/python3.5/site-packages/fuzzywuzzy/fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "from itertools import combinations\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 101)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x )\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src', 'data')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport utils\n",
    "%aimport download_planet_lib\n",
    "\n",
    "# load environment varibles\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographic Features\n",
    "\n",
    "For our first pass at the data, our area of interest is just **Nakuru** county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "engine = create_engine('postgresql://localhost/farmdrive')\n",
    "session = sessionmaker(bind=engine)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "county_name = 'Nakuru'\n",
    "crop_table = 'maiz_p--ssa'\n",
    "crop_name = 'maize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geometry': {'coordinates': [[[35.9166783844273, 0.083326218967615],\n",
       "    [36.0000117291493, 0.083326218967615],\n",
       "    [36.0000117291493, -7.12575437e-06],\n",
       "    [35.9166783844273, -7.12575437e-06],\n",
       "    [35.9166783844273, 0.083326218967615]]],\n",
       "  'crs': {'properties': {'name': 'EPSG:4326'}, 'type': 'name'},\n",
       "  'type': 'Polygon'},\n",
       " 'id': '8_3',\n",
       " 'properties': {'maize_yield': 1},\n",
       " 'type': 'Feature'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individual geojson polygons for each raster pixel\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "json_build_object(\n",
    "    'type', 'Feature',\n",
    "    'id', (poly_pixels.x || '_' || poly_pixels.y),\n",
    "    'geometry', ST_AsGeoJSON(1, poly_pixels.geom, 15, 2) :: JSON,\n",
    "    'properties', json_build_object('{crop_name}_yield', poly_pixels.val)\n",
    ")\n",
    "FROM\n",
    "  (SELECT (ST_PixelAsPolygons(ST_Union(ST_Clip(\"{crop_table}\".rast, clipped_geom.geom)))).*\n",
    "    FROM\n",
    "      \"{crop_table}\",\n",
    "      (SELECT county.geom FROM county WHERE county.county = '{county_name}') AS clipped_geom\n",
    "    WHERE ST_Intersects(\"{crop_table}\".rast, clipped_geom.geom)\n",
    "  ) AS poly_pixels;\n",
    "\"\"\"\n",
    "\n",
    "query = query.format(crop_name=crop_name,\n",
    "           crop_table=crop_table,\n",
    "           county_name=county_name)\n",
    "\n",
    "# Execute the query in the session\n",
    "result = session.execute(query)\n",
    "\n",
    "# for now, just get the first result. ultimately, we'll need them all.\n",
    "aoi_raster = result.fetchall()\n",
    "aoi_raster = aoi_raster[2]\n",
    "\n",
    "geojson_from_postgis = aoi_raster['json_build_object']\n",
    "geojson_from_postgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geojson_from_postgis['geometry']['coordinates'][0] = geojson_from_postgis['geometry']['coordinates'][0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from subprocess import check_output, CalledProcessError, STDOUT\n",
    "\n",
    "planet_data = os.path.join(os.pardir,\n",
    "                             'data',\n",
    "                             'raw',\n",
    "                             'planet')\n",
    "\n",
    "county_data = os.path.join(planet_data, county_name)\n",
    "\n",
    "county_pixel_dir = os.path.join(county_data,\n",
    "                                geojson_from_postgis['id'])\n",
    "\n",
    "asset_dir = os.path.join(county_data,\n",
    "                         'assets')\n",
    "\n",
    "os.makedirs(county_pixel_dir, exist_ok=True)\n",
    "\n",
    "geojson_input = os.path.join(county_pixel_dir, 'geojson_epsg4326.geojson')\n",
    "geojson_output = os.path.join(county_pixel_dir, 'geojson_epsg32637.geojson')\n",
    "\n",
    "with open(geojson_input, 'w') as gj_file:\n",
    "    json.dump(geojson_from_postgis, gj_file)\n",
    "\n",
    "try:\n",
    "    check_output(['ogr2ogr',\n",
    "                  '-f',\n",
    "                  'GeoJSON',\n",
    "                  geojson_output,\n",
    "                  '-t_srs',\n",
    "                  'EPSG:32637',\n",
    "                  geojson_input], stderr=STDOUT)\n",
    "\n",
    "except CalledProcessError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geo_json_geometry = geojson_from_postgis['geometry']\n",
    "\n",
    "# filter for items the overlap with our chosen geometry\n",
    "geometry_filter = {\n",
    "  \"type\": \"GeometryFilter\",\n",
    "  \"field_name\": \"geometry\",\n",
    "  \"config\": geo_json_geometry\n",
    "}\n",
    "\n",
    "# MAIZE harvest season in Kenya is Aug - Oct\n",
    "date_range_filter = {\n",
    "  \"type\": \"DateRangeFilter\",\n",
    "  \"field_name\": \"acquired\",\n",
    "  \"config\": {\n",
    "    \"gte\": \"2016-07-31T00:00:00.000Z\",\n",
    "    \"lte\": \"2016-10-31T00:00:00.000Z\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# filter any images which are more than 10% clouds\n",
    "cloud_cover_filter = {\n",
    "  \"type\": \"RangeFilter\",\n",
    "  \"field_name\": \"cloud_cover\",\n",
    "  \"config\": {\n",
    "    \"lte\": 0.05\n",
    "  }\n",
    "}\n",
    "\n",
    "# create a filter that combines our geo and date filters\n",
    "maize_filter = {\n",
    "  \"type\": \"AndFilter\",\n",
    "  \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def has_local_scene(scene_id, asset_type):\n",
    "    glob_path = os.path.join(asset_dir, '{}_{}.tif'.format(sid, asset_type))\n",
    "    scene_paths = glob(glob_path)    \n",
    "    return len(scene_paths) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Product type, PSOrthoTile or REOrthoTile\n",
    "search_type = 'PSOrthoTile'\n",
    "\n",
    "# visual or analytic - which asset type to download\n",
    "asset_type = 'analytic'\n",
    "\n",
    "\n",
    "# get the planet scenes for our query\n",
    "scene_ids = download_planet_lib.run_search({'item_types': [search_type],\n",
    "                                        'filter': maize_filter})\n",
    "\n",
    "# check for scenes that we _don't_ already have\n",
    "not_local_scene_ids = []\n",
    "for sid in scene_ids:\n",
    "    if not has_local_scene(sid, asset_type):\n",
    "        not_local_scene_ids.append(sid)\n",
    "    \n",
    "# activate all of the planet scenes that we may want\n",
    "res2 = download_planet_lib.process_activation(download_planet_lib.activate,\n",
    "                                          not_local_scene_ids,\n",
    "                                          search_type,\n",
    "                                          asset_type)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    resie = download_planet_lib.process_activation(download_planet_lib.check_activation,\n",
    "                                               not_local_scene_ids,\n",
    "                                               search_type,\n",
    "                                               asset_type)\n",
    "    \n",
    "    if all(resie):\n",
    "        print('Activated!')\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(15)\n",
    "\n",
    "results = download_planet_lib.process_download(asset_dir,\n",
    "                                           not_local_scene_ids,\n",
    "                                           search_type,\n",
    "                                           asset_type,\n",
    "                                           True)\n",
    "\n",
    "results\n",
    "assert all(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge tiles for each pixel and crop to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rasterio import windows\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "\n",
    "def my_merge(sources, bounds=None, res=None, nodata=None, precision=7):\n",
    "    first = sources[0]\n",
    "    first_res = first.res\n",
    "    nodataval = first.nodatavals[0]\n",
    "    dtype = first.dtypes[0]\n",
    "\n",
    "    # Extent from option or extent of all inputs.\n",
    "    if bounds:\n",
    "        dst_w, dst_s, dst_e, dst_n = bounds\n",
    "    else:\n",
    "        # scan input files.\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for src in sources:\n",
    "            left, bottom, right, top = src.bounds\n",
    "            xs.extend([left, right])\n",
    "            ys.extend([bottom, top])\n",
    "        dst_w, dst_s, dst_e, dst_n = min(xs), min(ys), max(xs), max(ys)\n",
    "\n",
    "    output_transform = Affine.translation(dst_w, dst_n)\n",
    "\n",
    "    # Resolution/pixel size.\n",
    "    if not res:\n",
    "        res = first_res\n",
    "    elif not np.iterable(res):\n",
    "        res = (res, res)\n",
    "    elif len(res) == 1:\n",
    "        res = (res[0], res[0])\n",
    "    output_transform *= Affine.scale(res[0], -res[1])\n",
    "\n",
    "    # Compute output array shape. We guarantee it will cover the output\n",
    "    # bounds completely.\n",
    "    output_width = int(math.ceil((dst_e - dst_w) / res[0]))\n",
    "    output_height = int(math.ceil((dst_n - dst_s) / res[1]))\n",
    "\n",
    "    # Adjust bounds to fit.\n",
    "    dst_e, dst_s = output_transform * (output_width, output_height)\n",
    "\n",
    "    # create destination array\n",
    "    dest = np.zeros((first.count, output_height, output_width), dtype=dtype)\n",
    "\n",
    "    if nodata is not None:\n",
    "        nodataval = nodata\n",
    "\n",
    "    if nodataval is not None:\n",
    "        # Only fill if the nodataval is within dtype's range.\n",
    "        inrange = False\n",
    "        if np.dtype(dtype).kind in ('i', 'u'):\n",
    "            info = np.iinfo(dtype)\n",
    "            inrange = (info.min <= nodataval <= info.max)\n",
    "        elif np.dtype(dtype).kind == 'f':\n",
    "            info = np.finfo(dtype)\n",
    "            inrange = (info.min <= nodataval <= info.max)\n",
    "        if inrange:\n",
    "            dest.fill(nodataval)\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                \"Input file's nodata value, %s, is beyond the valid \"\n",
    "                \"range of its data type, %s. Consider overriding it \"\n",
    "                \"using the --nodata option for better results.\" % (\n",
    "                    nodataval, dtype))\n",
    "    else:\n",
    "        nodataval = 0\n",
    "\n",
    "    for src in tqdm(sources):\n",
    "        # Real World (tm) use of boundless reads.\n",
    "        # This approach uses the maximum amount of memory to solve the problem.\n",
    "        # Making it more efficient is a TODO.\n",
    "\n",
    "        # 1. Compute spatial intersection of destination and source.\n",
    "        src_w, src_s, src_e, src_n = src.bounds\n",
    "\n",
    "        int_w = src_w if src_w > dst_w else dst_w\n",
    "        int_s = src_s if src_s > dst_s else dst_s\n",
    "        int_e = src_e if src_e < dst_e else dst_e\n",
    "        int_n = src_n if src_n < dst_n else dst_n\n",
    "\n",
    "        # 2. Compute the source window.\n",
    "        src_window = windows.from_bounds(\n",
    "            int_w, int_s, int_e, int_n, src.transform,\n",
    "            boundless=True, precision=precision)\n",
    "\n",
    "        # 3. Compute the destination window.\n",
    "        dst_window = windows.from_bounds(\n",
    "            int_w, int_s, int_e, int_n, output_transform,\n",
    "            boundless=True, precision=precision)\n",
    "\n",
    "\n",
    "        # 4. Initialize temp array.\n",
    "        tcount = first.count\n",
    "        trows, tcols = tuple(b - a for a, b in dst_window)\n",
    "\n",
    "        temp_shape = (tcount, trows, tcols)\n",
    "\n",
    "        temp = np.zeros(temp_shape, dtype=dtype)\n",
    "        temp = src.read(out=temp, window=src_window, boundless=False,\n",
    "                        masked=True)\n",
    "\n",
    "        # 5. Copy elements of temp into dest.\n",
    "        roff, coff = dst_window[0][0], dst_window[1][0]\n",
    "\n",
    "        region = dest[:, roff:roff + trows, coff:coff + tcols]\n",
    "        np.copyto(\n",
    "            region, temp,\n",
    "            where=np.logical_and(region == nodataval, temp.mask == False))\n",
    "\n",
    "    return dest, output_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"rasterio.merge\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# logging.Logger.manager.loggerDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-30059222b4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mreprojgeoj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgj_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mout_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreprojgeoj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# save the resulting raster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bull/rasterio/rasterio/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(sources, bounds, res, nodata, precision)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Temp shape: %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         temp = src.read(out=temp, window=src_window, boundless=False,\n\u001b[1;32m    169\u001b[0m                         masked=True)\n",
      "\u001b[0;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.merge import merge\n",
    "\n",
    "paths = [glob(county_data + os.sep + 'assets' + os.sep + '{}_{}.tif'.format(sid, asset_type))[0] \\\n",
    "    for sid in scene_ids]\n",
    "\n",
    "planet_crs = {'proj': 'utm', 'zone': 37, 'ellps': 'WGS84', 'datum': 'WGS84', 'units':'m', 'no_defs': True}\n",
    "srcs = [rasterio.open(p, crs=planet_crs) for p in paths]\n",
    "\n",
    "with open(geojson_output) as gj_file:\n",
    "    reprojgeoj = json.load(gj_file)\n",
    "\n",
    "out_image, out_transform = merge(srcs, bounds=features.bounds(reprojgeoj))\n",
    "\n",
    "# save the resulting raster\n",
    "out_meta = srcs[0].meta.copy()\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "    \"height\": out_image.shape[1],\n",
    "    \"width\": out_image.shape[2],\n",
    "    \"transform\": out_transform})\n",
    "\n",
    "raster_merged_path = os.path.join(county_pixel_dir, geojson_from_postgis['id'] + '.tif')\n",
    "\n",
    "with rasterio.open(raster_merged_path, \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bull/anaconda/envs/farmdrive/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2881: DeprecationWarning: 'src.affine' is deprecated.  Please switch to 'src.transform'. See https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<open DatasetReader name='../data/raw/planet/Nakuru/assets/273250_3739001_2016-10-21_0c76_analytic.tif' mode='r'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = srcs[0]\n",
    "a.affine\n",
    "a#.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop to pixels\n",
    "\n",
    "Now done using bounds above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import gdal\n",
    "\n",
    "# # Crop back to AOI\n",
    "# tif_loc = '../data/raw/planet/nakuru/11_1/271486_3739102_2016-10-19_0c65_analytic.tif'\n",
    "# output_file = os.path.splitext(tif_loc)[0] + '_clipped.tif'\n",
    "\n",
    "# import json\n",
    "# with open('../test.geojson', 'w') as tg:\n",
    "#     json.dump(aoi_raster['json_build_object'], tg)\n",
    "\n",
    "# # GDAL Warp crops the image by our AOI, and saves it\n",
    "# gdal.Warp(output_file,\n",
    "#           tif_loc,\n",
    "#           srcSRS = 'EPSG:32637',\n",
    "# #           dstSRS = 'WGS64',\n",
    "#           format='GTiff',\n",
    "#           dstAlpha=True,\n",
    "#           cutlineDSName='../test2.geojson',\n",
    "#           cropToCutline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from rasterio.mask import mask\n",
    "\n",
    "# # Crop back to AOI\n",
    "# tif_loc = '../data/raw/planet/nakuru/11_1/11_rio.tif'\n",
    "# output_file = os.path.splitext(tif_loc)[0] + '_clipped.tif'\n",
    "\n",
    "# with open('../test2.geojson') as tg:\n",
    "#     reprojgeoj = json.load(tg)\n",
    "\n",
    "# planet_crs = {'proj': 'utm', 'zone': 37, 'ellps': 'WGS84', 'datum': 'WGS84', 'units':'m', 'no_defs': True}\n",
    "# # load the raster, mask it by the polygon and crop it\n",
    "# with rasterio.open(tif_loc, crs=planet_crs) as src:\n",
    "#     out_image, out_transform = mask(src,\n",
    "#                                     [reprojgeoj],\n",
    "#                                     crop=True)\n",
    "    \n",
    "#     #plt.imshow(out_image)\n",
    "#     out_meta = src.meta.copy()\n",
    "\n",
    "# # save the resulting raster  \n",
    "# out_meta.update({\"driver\": \"GTiff\",\n",
    "#     \"height\": out_image.shape[1],\n",
    "#     \"width\": out_image.shape[2],\n",
    "#     \"transform\": out_transform})\n",
    "\n",
    "# with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "#     dest.write(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "test = ['a', 'b', 'c']\n",
    "mask = [True, False, True]\n",
    "\n",
    "list(compress(test, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:farmdrive]",
   "language": "python",
   "name": "conda-env-farmdrive-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
